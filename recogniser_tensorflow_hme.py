# -*- coding: utf-8 -*-
"""Recogniser_TensorFlow_HME.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yb8dqyI_ZssT-cHC86x-Ogr1qoUqUtvb

Gettting data from keggle
"""

! pip install kaggle

! mkdir ~/.kaggle

# Upload Kaggle.json u got from kaggle account before running this cell
! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

# Dataset No. 1 : more than 4.5 lakh images
! kaggle datasets download -d xainano/handwrittenmathsymbols

# Extract the data
!unzip /content/handwrittenmathsymbols.zip -d /content/dataset

!pip install unrar

# Extract the inner data part
!unrar x /content/dataset/data.rar

# Extracting all the symbol names from foldernames
import glob
from pathlib import Path
FOLDERS = glob.glob("/content/testing_dataset/dataset/*")
symbols = []
for i in FOLDERS:
 symbols.append( str(Path(i).stem))
print(symbols)

# Importing required modules
from tensorflow.keras.preprocessing.image import ImageDataGenerator
#from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2 as cv
import numpy as np
import datetime
from pathlib import Path
from google.colab.patches import cv2_imshow

import glob

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# Preprocessing dataset
train_path = "/content/testing_dataset/dataset"

train_datagen = ImageDataGenerator(
    rescale = 1./255, 
    shear_range = 0.2, 
    zoom_range = 0.2,
    validation_split = 0.25
)
train_set = train_datagen.flow_from_directory(
    train_path, 
    target_size = (45, 45), 
    color_mode = 'grayscale',
    batch_size = 32,
    class_mode = 'categorical',
    # classes = ['!', '(', ')', '+'],
    # classes = ['!', '(', ')', '+', ',', '-', '0'],
    # classes = ['geq', 'div', 'R', 'f', 'pm', 'ldots', 'C', 'e', '}', 'A', '(', 'H', 'lt', 'sigma', ',', 'gamma', 'j', 'times', 'leq', 'u', 'neq', '6', 'lim', 'o', 'infty', '0', 'ascii_124', 'cos', 'w', 'in', '{', 'gt', 'pi', 'prime', 'rightarrow', 'tan', 'exists', 'k', 'forward_slash', 'q', 'S', 'G', '8', 'theta', 'beta', 'N', 'phi', 'log', 'X', 'i', 'int', 'sin', 'l', '5', '4', 'Delta', '9', ')', 'sqrt', 'y', 'sum', 'mu', '=', '!', 'M', 'T', 'lambda', '-', 'b', '[', ']', 'z', 'forall', 'alpha', 'd', '3', '1', '7', 'p', '2', 'v', '+'],
    #classes = ['div', '(', 'times', '6', '0', 'cos', 'pi', '8', 'theta',  'log','sin', '5', '4', '9', ')', 'sqrt', '=',  '-', 'b',  'd', '3', '1', '7', '2', '+'],
    classes = ['4', 'z', 'div', '3', '7', 'sub', '1', 'x', '9', '2', 'y', 'add', '0', 'dec', 'eq', '8', '5', '6', 'mul'],
    shuffle = True,
    subset='training',
    seed = 123
)

test_set = train_datagen.flow_from_directory(
    train_path, 
    target_size = (45, 45), 
    color_mode = 'grayscale',
    batch_size = 32,
    class_mode = 'categorical',
    # classes = ['!', '(', ')', '+'],
    # classes = ['!', '(', ')', '+', ',', '-', '0'],
    #classes = ['geq', 'div', 'R', 'f', 'pm', 'ldots', 'C', 'e', '}', 'A', '(', 'H', 'lt', 'sigma', ',', 'gamma', 'j', 'times', 'leq', 'u', 'neq', '6', 'lim', 'o', 'infty', '0', 'ascii_124', 'cos', 'w', 'in', '{', 'gt', 'pi', 'prime', 'rightarrow', 'tan', 'exists', 'k', 'forward_slash', 'q', 'S', 'G', '8', 'theta', 'beta', 'N', 'phi', 'log', 'X', 'i', 'int', 'sin', 'l', '5', '4', 'Delta', '9', ')', 'sqrt', 'y', 'sum', 'mu', '=', '!', 'M', 'T', 'lambda', '-', 'b', '[', ']', 'z', 'forall', 'alpha', 'd', '3', '1', '7', 'p', '2', 'v', '+'],
    #classes = ['div', '(', 'times', '6', '0', 'cos', 'pi', '8', 'theta',  'log','sin', '5', '4', '9', ')', 'sqrt', '=',  '-', 'b',  'd', '3', '1', '7', '2', '+'],
     classes = ['4', 'z', 'div', '3', '7', 'sub', '1', 'x', '9', '2', 'y', 'add', '0', 'dec', 'eq', '8', '5', '6', 'mul'],
    shuffle = True,
    subset='validation',
    seed = 123
)

# Define the available symbols in the dataset
def symbol(ind):
    # symbols = ['!', '(', ')', '+']
    # symbols = ['!', '(', ')', '+', ',', '-', '0']
    #symbols = ['geq', 'div', 'R', 'f', 'pm', 'ldots', 'C', 'e', '}', 'A', '(', 'H', 'lt', 'sigma', ',', 'gamma', 'j', 'times', 'leq', 'u', 'neq', '6', 'lim', 'o', 'infty', '0', 'ascii_124', 'cos', 'w', 'in', '{', 'gt', 'pi', 'prime', 'rightarrow', 'tan', 'exists', 'k', 'forward_slash', 'q', 'S', 'G', '8', 'theta', 'beta', 'N', 'phi', 'log', 'X', 'i', 'int', 'sin', 'l', '5', '4', 'Delta', '9', ')', 'sqrt', 'y', 'sum', 'mu', '=', '!', 'M', 'T', 'lambda', '-', 'b', '[', ']', 'z', 'forall', 'alpha', 'd', '3', '1', '7', 'p', '2', 'v', '+']
    # symbols = ['div', '(', 'times', '6', '0', 'cos', 'pi', '8', 'theta',  'log','sin', '5', '4', '9', ')', 'sqrt', '=',  '-', 'b',  'd', '3', '1', '7', '2', '+']
    symbols =  ['4', 'z', 'div', '3', '7', 'sub', '1', 'x', '9', '2', 'y', 'add', '0', 'dec', 'eq', '8', '5', '6', 'mul']
    symb = symbols[ind.argmax()]
    return symb

# Verification if the data has been loaded properly
imgs, labels = next(train_set)

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 10, figsize = (20,20))
    axes = axes.flatten()
    for img, ax in zip(images_arr, axes):
        ax.imshow(cv.cvtColor(img, cv.COLOR_RGB2BGR))
        ax.axis('off')
    plt.tight_layout()
    plt.show()
    
plotImages(imgs)
print(symbol)
for i in range(32):
    print(symbol(labels[i]))

# Inilialize the model
model = tf.keras.models.Sequential()

# First Convolutional Block
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(45, 45, 1)))
model.add(tf.keras.layers.MaxPool2D(strides=2))

# Second Convolutional Block
model.add(tf.keras.layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))
model.add(tf.keras.layers.MaxPool2D(strides=2))

# Classifier Head
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256, activation='relu'))
model.add(tf.keras.layers.Dense(84, activation='relu'))
model.add(tf.keras.layers.Dense(19, activation='softmax'))

# Print model summary
model.summary()

# Set Tensorboad and optimizer
adam = tf.keras.optimizers.Adam(lr = 5e-4)
model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

# Training of the model
model.fit(train_set, validation_data = test_set, epochs = 20, callbacks=[tensorboard_callback])

# Commented out IPython magic to ensure Python compatibility.
# Launch the tensorboard for the visualisation of the training
# %tensorboard --logdir logs/fit

# saving and loading the .h5 model
from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model

# #save model
# model.save('HME_Symbol_Recog_small_dataset.h5')
# print('Model Saved!')
 
# load model
savedModel=load_model('/content/HME_Symbol_Recog_small_dataset.h5')
savedModel.summary()

# prediction function for the real-life data
def prediction(image_path):
    
    img = cv.imread(image_path, cv.IMREAD_GRAYSCALE)
    plt.imshow(img, cmap = 'gray')
    img = cv.resize(img,(45, 45))
    norm_image = cv.normalize(img, None, alpha = 0, beta = 1, norm_type = cv.NORM_MINMAX, dtype = cv.CV_32F)
    norm_image = norm_image.reshape((norm_image.shape[0], norm_image.shape[1], 1))
    case = np.asarray([norm_image])
    # pred = model.predict([case])    # use this for trained model locally
    pred = savedModel.predict([case]) # use this for pre trained uploaded model locally

    return  symbol(pred)

"""***Testing on custom dataset***"""

! kaggle datasets download -d sagyamthapa/handwritten-math-symbols

! unzip /content/handwritten-math-symbols.zip -d /content/testing_dataset

# New method for skeletonization

from skimage import img_as_float
from skimage import io, color, morphology
import matplotlib.pyplot as plt
from pylab import gray, imshow, show
from google.colab.patches import cv2_imshow
import cv2 
import pylab
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


def skeleton(img_path, ctr):
  image = img_as_float(color.rgb2gray(io.imread(img_path)))
  image_binary = image < 0.4
  out_skeletonize = morphology.skeletonize(image_binary)
  out_thin = morphology.thin(image_binary)


  # f, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(100, 30))

  # ax0.imshow(image, cmap='gray')
  # ax0.set_title('Input')

  # ax1.imshow(out_skeletonize, cmap='gray')
  # ax1.set_title('Skeletonize')
  # f, (ax2) = plt.subplots(1, 1, figsize=(100, 30))

  # ax2.imshow(out_thin, cmap='gray')
  # ax2.set_title('Thin')

  # plt.savefig('/tmp/char_out.png')
  # plt.show()


  plt.figure(figsize=(5, 5))
  plt.imshow(out_skeletonize, cmap='gray')
  plt.axis('off') 
  plt.savefig(r'/content/skeletonized/' + str(ctr)+ '.jpeg',bbox_inches =  'tight', pad_inches = 0)
  plt.show() # display it

# Bulk custom data prediction section

# path = '/content/Screenshot from 2022-02-13 11-31-24.png'
# ans = prediction(path)
# print(ans)

# symbols =  ['4: 89.33%', 'z', 'div', '3 : 80', '7', 'sub', '1:72', 'x', '9', '2', 'y', 'add', '0', 'dec', 'eq', '8', '5', '6', 'mul']
f = open("demofile2.txt", "w+")
f.write("hello")


#THIS IS THE WORKING PART
allsyms = ['4', 'z', 'div', '3', '7', 'sub', '1', '9', '2', 'y', 'add', '0', 'eq', '8', '5', '6', 'mul']
# allsyms = ['9', '2', 'y', 'add', '0', 'eq', '8', '5', '6', 'mul']
for s in allsyms:
  print(f"FOR {s}")
  INPUT_IMGS_Origin = glob.glob(r"/content/extracted_images/" + str(s) + "/*jpg")
  INPUT_IMGS_Origin.sort()
  correct = 0
  ctr = 0
  for i in INPUT_IMGS_Origin:
    ctr+=1
    ans = prediction(i)
    if ans == str(s):
      correct+=1
      print(f'{s} : {correct}/{ctr} -> {round(   (correct/ctr) * 100 ,2) }') 
  f.write(f'{s} : {correct}/{ctr} -> {round(   (correct/ctr) * 100 ,2) }%')

    
f.close()




# INPUT_IMGS_Origin = glob.glob("/content/extracted_images/5/*jpg")
# INPUT_IMGS_Skel = glob.glob("/content/skeletonized/*jpeg")
# INPUT_IMGS_Origin.sort()
# correct = 0
# ctr = 0
# for i in INPUT_IMGS_Origin:
#   ctr+=1
#   # print(ctr)
#   ans = prediction(i)
#   if ans == '5':
#      correct+=1
#      print(f'{correct}/{ctr} -> {round(   (correct/ctr) * 100 ,2) }%') 
  # print(ans)
# print(ctr, correct) 6914 5023
  
  #img = cv.imread(i)
  # cv2_imshow(img)


# print(ctr, correct) -> 469, 369

# print(f"Correct : {ctr}, Total : {len(INPUT_IMGS_Origin)}")
  # skeleton(i, ctr)

  # ans_o = prediction(i)
  # ans_s = prediction(j)
  # img_o = cv.imread(i)
  # img_s = cv.imread(j)

  # f, (ax1,ax2) = plt.subplots(1, 2, figsize=(10, 3))

  # ax1.imshow(img_o, cmap='gray')
  # ax1.set_title(str(ans_o))
  # ax2.imshow(img_s, cmap='gray')
  # ax2.set_title(str(ans_s))
  
  # plt.show()



  # print(ans)
  # if str(ans) == '0':
  #    correct += 1
  # img = cv.imread(i)
  # cv2_imshow(img)
# print(f'total {len(INPUT_IMGS)} , Correct : {correct}')
# img = cv.imread("/content/testing_dataset/dataset/0/10014.jpg")
# cv2_imshow(img)

import time
while True:
  print("working")
  time.sleep(1000)
! find /content/extracted_images/0 -type f | wc -l

# inversion of color
INPUT_IMGS = glob.glob("/content/skeletonized/*jpeg")
correct = 0
ctr = 0
for i in INPUT_IMGS:
  imgBW = cv.imread(i)
  invImg = cv.bitwise_not(imgBW)
  cv2_imshow(invImg)
  cv.imwrite(i, invImg)